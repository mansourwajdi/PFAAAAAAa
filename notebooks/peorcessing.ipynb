{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from python_speech_features import mfcc\n",
    "from CQCC.cqcc import cqcc\n",
    "import scipy.io.wavfile as wav\n",
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from embedding import *\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_path\", required=True, type=str,\n",
    "                    help='path to data . For example,../Data/LA_CSV/train.csv')\n",
    "parser.add_argument(\"--type\", required=True, type=str, help='type of data :train,dev or eval')\n",
    "args = parser.parse_args()\n",
    "\n",
    "data = pd.read_csv(args.data_path)\n",
    "feats = []\n",
    "total_samples = len(data['filepath'])\n",
    "progress_bar = tqdm(total=total_samples, bar_format='{l_bar}{bar:20}{r_bar}', desc=f\"Preprocessing Audio\",\n",
    "                    unit=\"files\")\n",
    "for filepath in data['filepath']:\n",
    "    signal, rate = sf.read(filepath[3:])\n",
    "    mask = envelope(signal, rate, 0.0005)\n",
    "    signal = signal[mask]\n",
    "    feats_mfcc = compute_mfcc(signal[:2 * rate], rate)\n",
    "    feats_mfcc = compute_feature_sequence_embedding(feats_mfcc, mean=True, variance=True, avg_diff=True)\n",
    "    feats.append(feats_mfcc)\n",
    "    progress_bar.update(1)\n",
    "progress_bar.close()\n",
    "feats = pd.DataFrame(feats)\n",
    "feats['target'] = data['target'].values\n",
    "if args.type == 'train':\n",
    "    feats.to_csv('Data/features/' + args.type + 'feats.csv', index=False)\n",
    "else:\n",
    "    feats['system_id'] = data['system_id'].values\n",
    "    feats.to_csv('Data/features/' + args.type + 'feats.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdd5087bbedf73de"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "4705a5782d5b09fe"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pickle\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.mixture import GaussianMixture as GMM\n",
    "from sklearn.mixture import BayesianGaussianMixture as DPGMM\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"--data_path\", required=True, type=str, help='path to pickled file. For example, data/train.pkl')\n",
    "\n",
    "args = parser.parse_args()\n",
    "\n",
    "data = pd.read_csv(args.data_path)\n",
    "y = data['target'].values\n",
    "X = data.drop(['target'], axis=1).values\n",
    "\n",
    "print('SVM training started...')\n",
    "clf = SVC(class_weight='balanced')\n",
    "clf.fit(X, y)\n",
    "print('SVM training completed.')\n",
    "\n",
    "with open('models/svm.pkl', 'wb') as outfile:\n",
    "    pickle.dump(clf, outfile)\n",
    "\n",
    "# Train GMM for class 0 (bon)\n",
    "print('GMM training for class 0 (bon) started...')\n",
    "gmm_bon = GMM(n_components=144, covariance_type='diag', n_init=50)\n",
    "Xbon = data[data['target'] == 0].drop(['target'], axis=1).values\n",
    "gmm_bon.fit(Xbon)\n",
    "print('GMM training for class 0 (bon) completed.')\n",
    "\n",
    "# Train GMM for class 1 (sp)\n",
    "print('GMM training for class 1 (sp) started...')\n",
    "gmm_sp = GMM(n_components=144, covariance_type='diag', n_init=50)\n",
    "Xsp = data[data['target'] == 1].drop(['target'], axis=1).values\n",
    "gmm_sp.fit(Xsp)\n",
    "print('GMM training for class 1 (sp) completed.')\n",
    "\n",
    "# Train DPGMM for class 0 (bon)\n",
    "print('DPGMM training for class 0 (bon) started...')\n",
    "dpgmm_bon = DPGMM(n_components=144, covariance_type='diag', n_init=50, weight_concentration_prior_type='dirichlet_process')\n",
    "dpgmm_bon.fit(Xbon)\n",
    "print('DPGMM training for class 0 (bon) completed.')\n",
    "\n",
    "# Train DPGMM for class 1 (sp)\n",
    "print('DPGMM training for class 1 (sp) started...')\n",
    "dpgmm_sp = DPGMM(n_components=144, covariance_type='diag', n_init=50, weight_concentration_prior_type='dirichlet_process')\n",
    "dpgmm_sp.fit(Xsp)\n",
    "print('DPGMM training for class 1 (sp) completed.')\n",
    "\n",
    "# Save models\n",
    "pickle.dump(gmm_bon, open('models/bon_gmm.pkl', 'wb'))\n",
    "pickle.dump(gmm_sp, open('models/sp_gmm.pkl', 'wb'))\n",
    "pickle.dump(dpgmm_bon, open('models/bon_dpgmm.pkl', 'wb'))\n",
    "pickle.dump(dpgmm_sp, open('models/sp_dpgmm.pkl', 'wb'))\n",
    "\n",
    "print('GMM and DPGMM models created')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d358613eed813510"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
